{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of users: 6040, num of items: 3952\n",
      "Successfully create Training Env!\n"
     ]
    }
   ],
   "source": [
    "from data_util import read_file\n",
    "from environment import *\n",
    "# from env import *\n",
    "from ddpg import *\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "data_name = 'ml-1m'\n",
    "data = read_file('./data/'+data_name+'/train_data.csv')\n",
    "item_embeddings = np.load('./data/'+data_name+'/item_embed.npy')\n",
    "user_embeddings = np.load('./data/'+data_name+'/user_embed.npy')\n",
    "\n",
    "\n",
    "nb_item = item_embeddings.shape[0]\n",
    "nb_user = user_embeddings.shape[0]\n",
    "print('num of users: %d, num of items: %d' %(nb_user, nb_item))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "env_args = {}\n",
    "env_args['data'] = data\n",
    "env_args['nb_user'] = nb_user\n",
    "env_args['nb_item'] = nb_item\n",
    "env_args['item_embeddings'] = item_embeddings\n",
    "env_args['user_embeddings'] = user_embeddings\n",
    "env_args['device'] = device\n",
    "env_args['gamma'] = 0.95\n",
    "\n",
    "env = Environment(**env_args)\n",
    "print('Successfully create Training Env!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of state space: 500, size of action space: 100\n",
      "60400\n",
      "# of episode:1, avg score: 2140.30, time: 5.20s\n",
      "tensor([[1618, 3116, 2324,  ..., 2231, 3948, 3538],\n",
      "        [1187, 3879, 2231,  ..., 2164,  696, 3948],\n",
      "        [2963, 2164, 3948,  ...,   47,   91, 2249],\n",
      "        ...,\n",
      "        [2571, 2494, 3538,  ..., 2386,   23, 1388],\n",
      "        [ 124, 2383, 3042,  ..., 3202, 3652,   96],\n",
      "        [3690, 2383, 1524,  ..., 1859, 2231, 2317]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fb5a249301b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_embeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_idxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mstates_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_idxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;31m#         states_prime, rewards, info = env.step(item_idxes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/LIRD-master/v1.3_PMF_prediction/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions, item_idxes)\u001b[0m\n\u001b[1;32m     40\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_idxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   4369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4370\u001b[0m         \u001b[0;31m# optimization for a single value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4371\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mN\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4373\u001b[0m             raise IndexError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_length = 5 # N in article\n",
    "ra_length = 1 # K in article\n",
    "state_space_size = item_embeddings.shape[1] * history_length\n",
    "action_space_size = item_embeddings.shape[1] * ra_length\n",
    "print('size of state space: %d, size of action space: %d' %(state_space_size, action_space_size))\n",
    "\n",
    "#Hyperparameters\n",
    "lr_mu        = 1e-5\n",
    "lr_q         = 1e-4\n",
    "gamma        = 0.99\n",
    "batch_size   = 1000\n",
    "buffer_limit = 100000\n",
    "tau          = 5e-3 # for target network soft update\n",
    "\n",
    "memory = ReplayBuffer(buffer_limit)\n",
    "\n",
    "q, q_target = QNet(state_space_size, action_space_size).cuda(), QNet(state_space_size, action_space_size).to(device)\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "mu, mu_target = MuNet(state_space_size, action_space_size).to(device), MuNet(state_space_size, action_space_size).to(device)\n",
    "mu_target.load_state_dict(mu.state_dict())\n",
    "\n",
    "score = 0.0\n",
    "print_interval = 1\n",
    "\n",
    "mu_optimizer = optim.Adam(mu.parameters(), lr=lr_mu)\n",
    "q_optimizer  = optim.Adam(q.parameters(), lr=lr_q)\n",
    "\n",
    "item_embeds = torch.from_numpy(item_embeddings).to(device).float()\n",
    "len_trajectory = 10\n",
    "epsilon = 0.9\n",
    "\n",
    "start = time.time()\n",
    "for n_epi in range(100):\n",
    "    n_epi = n_epi + 1\n",
    "    states = env.reset()\n",
    "    done = [False] * nb_user\n",
    "    recommended_item_onehot = torch.FloatTensor(nb_user, nb_item).zero_().to(device)\n",
    "    recommendations = []\n",
    "    for t in range(len_trajectory): \n",
    "        if np.random.rand() <= epsilon:\n",
    "            w = mu(torch.from_numpy(states).float().to(device))\n",
    "\n",
    "    #         item_idxes = torch.argmax(torch.mm(w.view(-1,item_embeddings.size()), item_embeds).view(nb_user,ra_length,-1),dim=2)\n",
    "    #         item_weights = torch.sigmoid(torch.mm(w.view(-1,item_embeddings.size()), item_embeds))\n",
    "            item_weights = torch.mm(w.view(-1,item_embeds.shape[1]), item_embeds.transpose(0,1)).view(nb_user, ra_length, -1)\n",
    "            item_weights = torch.mul(item_weights.transpose(0,1), 1-recommended_item_onehot).reshape(states.shape[0],ra_length,-1)\n",
    "\n",
    "            item_idxes = torch.argmax(item_weights,dim=2)\n",
    "        else:\n",
    "            item_weights = torch.FloatTensor(states.shape[0], ra_length, nb_item).uniform_(0, 1).to(device)\n",
    "            item_weights = torch.mul(item_weights.transpose(0,1), 1-recommended_item_onehot).reshape(states.shape[0],ra_length,-1)\n",
    "            item_idxes = torch.argmax(item_weights,dim=2)\n",
    "\n",
    "        recommendations.append(item_idxes)\n",
    "        recommended_item_onehot = recommended_item_onehot.scatter_(1, item_idxes, 1)\n",
    "\n",
    "        actions = item_embeds[item_idxes.cpu().detach()]\n",
    "        states_prime, rewards, info = env.step(actions, item_idxes)\n",
    "#         states_prime, rewards, info = env.step(item_idxes)\n",
    "        \n",
    "        if t == len_trajectory-1:\n",
    "            done = [True] * nb_user\n",
    "        \n",
    "        for s,a,r,s_prime,do in zip(states, actions, rewards, states_prime, done):\n",
    "#             if r == 0:\n",
    "#                 continue\n",
    "                \n",
    "            memory.put((s,a,r,s_prime,do))\n",
    "            \n",
    "        score += torch.sum(info).detach().cpu()\n",
    "        states = states_prime\n",
    "        \n",
    "    print(memory.size())          \n",
    "    if memory.size()>50000:\n",
    "        for i in range(10):\n",
    "            train(mu, mu_target, q, q_target, memory, q_optimizer, mu_optimizer, batch_size, gamma)\n",
    "            soft_update(mu, mu_target, tau)\n",
    "            soft_update(q,  q_target, tau)\n",
    "\n",
    "    if n_epi%print_interval==0 :\n",
    "        end = time.time()\n",
    "        print(\"# of episode:{}, avg score: {:.2f}, time: {:.2f}s\".format(n_epi, score/print_interval/len_trajectory, end-start))\n",
    "        print(torch.cat(recommendations,1))\n",
    "        score = 0.0\n",
    "        start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(128., device='cuda:0')\n",
      "tensor([[[2383, 3563]],\n",
      "\n",
      "        [[1463, 3798]],\n",
      "\n",
      "        [[2383, 3919]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[3798,   91]],\n",
      "\n",
      "        [[2231, 2958]],\n",
      "\n",
      "        [[2616, 2383]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from env import *\n",
    "with torch.no_grad():  \n",
    "    test_data = read_file('./data/'+data_name+'/test_data.csv')\n",
    "    test_env_args = {}\n",
    "    test_env_args['data'] = test_data\n",
    "    test_env_args['nb_user'] = nb_user\n",
    "    test_env_args['nb_item'] = nb_item\n",
    "    test_env_args['item_embeddings'] = item_embeddings\n",
    "    test_env_args['user_embeddings'] = user_embeddings\n",
    "    test_env_args['gamma'] = 0.95\n",
    "    test_env_args['device'] = device\n",
    "\n",
    "\n",
    "    test_env = Environment(**test_env_args)\n",
    "    test_states = test_env.reset()\n",
    "    \n",
    "#     rand_state = torch.FloatTensor(test_states.shape[0],test_states.shape[1],test_states.shape[2]).uniform_(0, 1)\n",
    "#     test_state = rand_state\n",
    "\n",
    "    \n",
    "    w = mu(torch.from_numpy(test_states).float().to(device)) \n",
    "\n",
    "#     item_idxes = torch.argmax(torch.mm(w.view(-1,item_embeddings.shape[1]), item_embeds.transpose(0,1)).view(nb_user,ra_length,-1),dim=2)\n",
    "#     actions = item_embeds[item_idxes.cpu().detach()]\n",
    "\n",
    "    k = 2\n",
    "    item_values, item_idxes = torch.topk(torch.mm(w.view(-1,item_embeddings.shape[1]), item_embeds.transpose(0,1)).view(nb_user,ra_length,-1), k, dim=2)\n",
    "\n",
    "    states_prime, _, test_info = test_env.step(item_idxes.view(nb_user,-1))\n",
    "    states = states_prime\n",
    "    print(torch.sum(test_info))\n",
    "    print(item_idxes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  16,   17,   18,   23,   24,   27,   47,   54,   62,   83,   91,   96,\n",
       "          151,  155,  165,  174,  179,  201,  202,  207,  213,  230,  233,  236,\n",
       "          248,  259,  265,  287,  308,  319,  335,  343,  356,  365,  406,  416,\n",
       "          428,  495,  503,  508,  512,  514,  531,  532,  535,  554,  589,  610,\n",
       "          669,  673,  679,  696,  717,  734,  735,  736,  837,  846,  884,  895,\n",
       "          900,  919,  923,  967, 1026, 1034, 1058, 1084, 1113, 1151, 1172, 1182,\n",
       "         1185, 1193, 1198, 1204, 1205, 1210, 1212, 1214, 1242, 1244, 1250, 1252,\n",
       "         1260, 1284, 1295, 1297, 1309, 1310, 1328, 1346, 1348, 1353, 1360, 1370,\n",
       "         1372, 1373, 1386, 1388, 1390, 1393, 1397, 1405, 1406, 1444, 1445, 1453,\n",
       "         1463, 1482, 1524, 1534, 1537, 1561, 1574, 1599, 1604, 1610, 1623, 1638,\n",
       "         1645, 1654, 1672, 1680, 1693, 1720, 1725, 1742, 1795, 1811, 1823, 1825,\n",
       "         1833, 1844, 1859, 1886, 1896, 1904, 1920, 1922, 1965, 1969, 1977, 1998,\n",
       "         2002, 2020, 2023, 2032, 2035, 2062, 2067, 2072, 2075, 2087, 2092, 2106,\n",
       "         2118, 2121, 2135, 2142, 2150, 2153, 2158, 2161, 2164, 2169, 2191, 2192,\n",
       "         2194, 2231, 2233, 2249, 2252, 2255, 2259, 2262, 2274, 2289, 2294, 2313,\n",
       "         2317, 2324, 2329, 2335, 2336, 2339, 2353, 2362, 2376, 2382, 2383, 2385,\n",
       "         2386, 2430, 2435, 2451, 2457, 2459, 2477, 2494, 2496, 2525, 2528, 2556,\n",
       "         2570, 2592, 2593, 2599, 2613, 2616, 2623, 2627, 2646, 2649, 2653, 2656,\n",
       "         2664, 2666, 2690, 2694, 2704, 2706, 2712, 2717, 2722, 2729, 2764, 2766,\n",
       "         2776, 2785, 2788, 2797, 2812, 2829, 2839, 2843, 2850, 2855, 2856, 2861,\n",
       "         2863, 2876, 2892, 2925, 2927, 2931, 2933, 2934, 2941, 2958, 2960, 2965,\n",
       "         2984, 2986, 3007, 3012, 3042, 3047, 3052, 3057, 3080, 3082, 3107, 3116,\n",
       "         3133, 3141, 3145, 3149, 3155, 3159, 3184, 3202, 3205, 3207, 3215, 3222,\n",
       "         3223, 3224, 3237, 3259, 3265, 3267, 3274, 3286, 3299, 3302, 3319, 3321,\n",
       "         3387, 3393, 3427, 3455, 3458, 3482, 3502, 3519, 3534, 3538, 3543, 3553,\n",
       "         3563, 3568, 3570, 3572, 3576, 3594, 3597, 3616, 3617, 3618, 3625, 3635,\n",
       "         3652, 3665, 3671, 3674, 3675, 3676, 3682, 3689, 3691, 3695, 3716, 3731,\n",
       "         3738, 3739, 3745, 3751, 3758, 3784, 3787, 3797, 3798, 3816, 3821, 3822,\n",
       "         3823, 3832, 3850, 3879, 3885, 3895, 3907, 3909, 3919, 3927, 3933, 3942,\n",
       "         3944, 3948, 3949], device='cuda:0'),\n",
       " tensor([   2,    2,    2,    6,    1,    9,  114,    1,    2,   11,   92,   61,\n",
       "           45,    1,    1,    1,    2,  157,    1,   16,    2,    5,    4,    2,\n",
       "           35,    1,    1,    7,    7,    2,   44,    4,    1,    1,    1,  145,\n",
       "          128,    2,    3,   37,    1,   15,    1,    2,   17,    4,    1,    1,\n",
       "            1,   31,    2,   10,   12,   66,    1,    5,    2,   18,    2,    2,\n",
       "            2,    6,   11,   10,  159,   10,    2,   33,   10,    1,    1,    5,\n",
       "            1,    1,   11,    7,  113,   14,    1,    5,    3,    5,    1,    1,\n",
       "            1,    2,    4,   26,    2,   21,    3,    2,    4,   10,   14,    9,\n",
       "            1,    2,    1,    1,   25,    7,   17,    3,   41,    3,    8,   11,\n",
       "          503,   27,  114,    1,    8,    2,    1,    6,    9,    1,    1,    1,\n",
       "            4,    3,    1,  202,    5,   14,    4,   34,    1,    8,    3,    1,\n",
       "            1,    1,    1,    1,    6,    1,   95,    1,    2,    1,    1,    7,\n",
       "            1,   29,    1,    3,    2,    1,    3,    1,    5,    1,    1,    1,\n",
       "           26,    2,    1,   15,    8,    2,   13,   39,  534,    1,    1,    1,\n",
       "            5, 1749,    1,   20,    7,   26,    3,   31,  136,    8,    3,    1,\n",
       "          267,    7,    1,    1,    3,   38,    6,    4,    3,   11, 1246,    3,\n",
       "          394,    2,    1,   15,    5,    8,    3,   82,    1,   83,    3,    1,\n",
       "           45,    1,   32,    1,    2,    5,    6,    4,    1,    2,    2,   36,\n",
       "            1,    1,    1,    3,    1,    2,    4,    1,    6,    9,    1,   85,\n",
       "            1,   17,    1,    1,    1,    1,    1,    7,    3,    1,    1,   59,\n",
       "           86,   39,    8,   19,    1,    6,    1,    1,    1,  140,  124,    1,\n",
       "            3,    3,    1,   12,  189,    3,    2,    1,    2,    1,    1,  146,\n",
       "            1,    7,   45,   20,    4,    4,    9,    4,    4,    4,    2,    2,\n",
       "            2,   34,    5,   24,    2,    1,    1,    1,    1,    2,   10,    2,\n",
       "            1,    1,    5,    1,    5,   28,    1,    1,    2, 1353,    1,    1,\n",
       "           26,    2,   25,    1,    6,    1,    1,   17,   11,   37,   97,    1,\n",
       "           56,    1,    1,    1,    2,    4,    6,    5,    6,    1,    1,    1,\n",
       "            1,    1,    1,    2,    1,    1,    7,    3,  664,    1,    6,    4,\n",
       "            7,   37,    1,    5,    3,    2,    3,   38,   36,    2,    1,    1,\n",
       "            6,  481,    1], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(item_idxes, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
